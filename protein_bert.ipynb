{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"preprocessed_data3.csv\")\n",
    "\n",
    "# Ensure 'Severity' column exists\n",
    "if 'Severity' not in df.columns:\n",
    "    raise ValueError(\"The dataset must contain a 'Severity' column.\")\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df[['AminoBefore', 'AminoAfter']]\n",
    "y = df['Severity']\n",
    "\n",
    "# Load pretrained Protein BERT model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Rostlab/prot_bert\")\n",
    "model = AutoModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "\n",
    "# Function to get embeddings for a sequence\n",
    "def get_embeddings(sequence):\n",
    "    encoded_input = tokenizer(sequence, return_tensors='pt', padding=True, truncation=True, max_length=218)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_input)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Generate embeddings for original and mutated sequences\n",
    "def generate_embeddings(sequences):\n",
    "    embeddings = []\n",
    "    for i, seq in enumerate(sequences):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Embedding sequence {i}: {seq}\")\n",
    "        embeddings.append(get_embeddings(seq))\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Convert sequences to lists of strings\n",
    "X_sequences_before = X['AminoBefore'].astype(str).tolist()\n",
    "X_sequences_after = X['AminoAfter'].astype(str).tolist()\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"Generating embeddings for sequences...\")\n",
    "original_embeddings = generate_embeddings(X_sequences_before)\n",
    "mutated_embeddings = generate_embeddings(X_sequences_after)\n",
    "diff_embeddings = mutated_embeddings - original_embeddings\n",
    "\n",
    "# Initialize MLP classifier\n",
    "mlp_classifier = MLPClassifier(\n",
    "    hidden_layer_sizes=(100),\n",
    "    max_iter=300,\n",
    "    random_state=42)\n",
    "\n",
    "# Initialize StratifiedKFold with shuffling\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(mlp_classifier, diff_embeddings, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "# Print cross-validation results\n",
    "print(f\"Cross-Validation Accuracy Scores: {cv_scores}\")\n",
    "print(f\"Mean Cross-Validation Accuracy: {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}\")\n",
    "\n",
    "# Fit the model on the entire data\n",
    "mlp_classifier.fit(diff_embeddings, y)\n",
    "\n",
    "# Split the data (for reporting purposes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(diff_embeddings, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_mlp = mlp_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate MLP classifier\n",
    "mlp_accuracy = accuracy_score(y_test, y_pred_mlp)\n",
    "mlp_classification_report = classification_report(y_test, y_pred_mlp)\n",
    "\n",
    "print(f\"MLP Accuracy on Test Data: {mlp_accuracy:.4f}\")\n",
    "print(\"MLP Classification Report on Test Data:\")\n",
    "print(mlp_classification_report)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
